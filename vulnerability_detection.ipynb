{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vulnerability Detection"
      ],
      "metadata": {
        "id": "NaiEJ7s62dER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zppwvue-cBuL"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\" # this is needed to get rid of weird colab locale error\n",
        "# if you are still running into issues, please restart the runtime to initialize a new environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain data\n",
        "!wget https://github.com/uiuc-cs598lmz-s24/hw4/raw/main/d2a.zip"
      ],
      "metadata": {
        "id": "snVHgvZFU88t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip d2a.zip"
      ],
      "metadata": {
        "id": "EKMZm3wCdHxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForCausalLM, T5ForConditionalGeneration\n",
        "\n",
        "def load_codet5_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base-codexglue-defect\").cuda()\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_codet5_model()\n"
      ],
      "metadata": {
        "id": "Htup6Xj5ZLqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example test using the small model\n",
        "\n",
        "code_snippets = \"\"\"\n",
        "#include <stdio.h>\n",
        "int main()\n",
        "{\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "input_tensor = tokenizer.encode(code_snippets, return_tensors='pt').to(\"cuda\")\n",
        "x = model.generate(input_tensor, max_length=50, temperature=1)\n"
      ],
      "metadata": {
        "id": "xeZRUs4nwlV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import json\n",
        "\n",
        "def prepare_vuln_dataset():\n",
        "    vuln_dataset = []\n",
        "    for file in glob.glob(\"d2a/*/src.c\"):\n",
        "        with open(file, \"r\") as f:\n",
        "          src = f.read()\n",
        "\n",
        "        with open(file.replace(\"src.c\",\"meta_data.json\"), \"r\") as f:\n",
        "          x = json.load(f)\n",
        "\n",
        "        x['src'] = src\n",
        "        vuln_dataset.append(x)\n",
        "\n",
        "    return vuln_dataset\n",
        "\n",
        "\n",
        "vuln_dataset = prepare_vuln_dataset()"
      ],
      "metadata": {
        "id": "V3BCox8WdOoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def predict_vuln(code: str, model, tokenizer) -> bool:\n",
        "    # TODO: implement greedy prediction of the model\n",
        "    # The return value should either be True (code contains a vulnerability)\n",
        "    # or False (code does not contain a vulnerability)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "def codet5_vuln_detection(model, tokenizer, vuln_dataset) -> float:\n",
        "\n",
        "  # TODO add neccessary local variables\n",
        "\n",
        "  for data in tqdm(vuln_dataset):\n",
        "      code = data['src']\n",
        "      gt_prediction = data['vulnerable']\n",
        "      vulnerability_type = data['vulnerability_type']\n",
        "\n",
        "      prediction = predict_vuln(code, model, tokenizer)\n",
        "\n",
        "  # TODO: compute F1 score\n",
        "\n",
        "# F1 score of codet5\n",
        "f1_score = codet5_vuln_detection(model, tokenizer, vuln_dataset)"
      ],
      "metadata": {
        "id": "RUHkSvn20caK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt-based Vulnerability Detection"
      ],
      "metadata": {
        "id": "2PAyVz_rIUOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"YOUR_API_KEY_HERE\")\n",
        "gemini = genai.GenerativeModel(\"models/gemini-pro\")"
      ],
      "metadata": {
        "id": "jpfJFJJ_gbPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import signal\n",
        "import time\n",
        "from google.generativeai import GenerationConfig\n",
        "\n",
        "safety_settings = [ # google is afraid of pretty much everything i think.\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "def create_gemini_config(\n",
        "    max_tokens: int,\n",
        "    temperature: float = 1,\n",
        "    batch_size: int = 1,\n",
        "):\n",
        "    config = GenerationConfig(\n",
        "        candidate_count=batch_size,\n",
        "        max_output_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return config\n",
        "\n",
        "\n",
        "def handler(signum, frame):\n",
        "    # swallow signum and frame\n",
        "    raise Exception(\"end of time\")\n",
        "\n",
        "\n",
        "def request_gemini_engine(model, message, config):\n",
        "    ret = None\n",
        "    count = 0\n",
        "    while ret is None:\n",
        "        try:\n",
        "            signal.signal(signal.SIGALRM, handler)\n",
        "            signal.alarm(100)\n",
        "            ret = model.generate_content(message, generation_config=config, safety_settings=safety_settings)\n",
        "            s = ret.text  # check if response can be accessed.\n",
        "            signal.alarm(0)\n",
        "        except Exception as e:\n",
        "            # NOTE this exception handling is needed since sometimes gemini will\n",
        "            # refuse to answer due to safety reason (even if all blockers are set off)\n",
        "            # instead we just simply catch this and then retry the response.\n",
        "            # don't be alarmed if certain inputs take a long time to finish\n",
        "            # eventually it should return a response.\n",
        "            ret = None  # reset\n",
        "            signal.alarm(0)\n",
        "            time.sleep(20)\n",
        "    return ret"
      ],
      "metadata": {
        "id": "9Nonr4zEgsy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_vuln_gemini(code: str, gemini) -> bool:\n",
        "    # TODO: temperature = 1 binary prediction of Gemini\n",
        "    # The return value should either be True (code contains a vulnerability)\n",
        "    # or False (code does not contain a vulnerability)\n",
        "    config = create_gemini_config(\n",
        "      max_tokens=100,\n",
        "      temperature=1,\n",
        "      batch_size=1,\n",
        "    )\n",
        "\n",
        "    formatted_input = f\"{code}\" # TODO add your instructions to the model\n",
        "\n",
        "    ret = request_gemini_engine(gemini, formatted_input, config)\n",
        "    gemini_response = ret.text\n",
        "\n",
        "    # TODO parse output to obtain prediction of either True or False\n",
        "    return prediction\n",
        "\n",
        "\n",
        "def gemini_vuln_detection(gemini, vuln_dataset) -> float:\n",
        "\n",
        "  # TODO add neccessary local variables\n",
        "\n",
        "  for data in tqdm(vuln_dataset):\n",
        "      code = data['src']\n",
        "      gt_prediction = data['vulnerable']\n",
        "      vulnerability_type = data['vulnerability_type']\n",
        "\n",
        "      prediction = predict_vuln_gemini(code, gemini)\n",
        "\n",
        "  # TODO: compute F1 score\n",
        "\n",
        "# F1 score of gemini\n",
        "gemini_f1_score = gemini_vuln_detection(gemini, vuln_dataset)"
      ],
      "metadata": {
        "id": "EAYLvxgihhiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_vuln_gemini_multi(code: str, gemini) -> str:\n",
        "    # TODO: temperature = 1 multi-class prediction of Gemini\n",
        "    # The return value shoud be a str which corresponding to one of the\n",
        "    # vulnerability types\n",
        "    config = create_gemini_config(\n",
        "      max_tokens=100,\n",
        "      temperature=1,\n",
        "      batch_size=1,\n",
        "    )\n",
        "\n",
        "    formatted_input = f\"{code}\" # TODO add your instructions to the model\n",
        "\n",
        "    ret = request_gemini_engine(gemini, formatted_input, config)\n",
        "    gemini_response = ret.text\n",
        "\n",
        "    # TODO parse output to obtain prediction as a string\n",
        "    return prediction\n",
        "\n",
        "\n",
        "def gemini_vuln_detection_multi(gemini, vuln_dataset) -> list:\n",
        "\n",
        "  # TODO add neccessary local variables\n",
        "\n",
        "  for data in tqdm(vuln_dataset):\n",
        "      code = data['src']\n",
        "      gt_prediction = data['vulnerable']\n",
        "      vulnerability_type = data['vulnerability_type']\n",
        "      print(vulnerability_type)\n",
        "\n",
        "      # pick from these types ['Integer-Overflow', 'Buffer-Overflow', 'Null-Pointer-Dereference', 'Resource-Exhaustion-Error', 'No-Vulnerability']\n",
        "\n",
        "      prediction = predict_vuln_gemini(code, gemini)\n",
        "\n",
        "  # TODO: compute accuracy of classifying each of these vulnerabilities\n",
        "\n",
        "gemini_multi_class_vulnerability = gemini_vuln_detection_multi(gemini, vuln_dataset)"
      ],
      "metadata": {
        "id": "zQihR3GAga0R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}